{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo notebook: \n",
    "## Facial landmarking - Active Appearance Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General configuration\n",
    "import os\n",
    "\n",
    "# data_directory: str\n",
    "#     Path to a directory to store data.\n",
    "data_directory = '.'\n",
    "\n",
    "\n",
    "# webcam: int\n",
    "#     An integer indicating the number of the webcam to be used. If there is just\n",
    "#     one webcam, this will usually be 0.\n",
    "webcam = 0\n",
    "\n",
    "\n",
    "# install_missing_packages: bool\n",
    "#     A flag indicating if missing packages should be automatically installed\n",
    "install_missing_packages = True\n",
    "\n",
    "\n",
    "# use_conda: bool\n",
    "#     A flag indicating if conda should be used for software installation.\n",
    "#     If False, pip will be used. The default is to use conda if jupyter\n",
    "#     is run in a conda environment.\n",
    "use_conda = 'CONDA_EXE' in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An auxiliary function to check for an install packages if missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "def check_package(package, pip_pkg: str = None, conda_pkg: str = None):\n",
    "    \"\"\"Check if a given package is installed. If missing install\n",
    "    it (if global flag `install_missing_packages` is True) either with\n",
    "    pip or with conda (depending on `use_conda`).\n",
    "    \"\"\"\n",
    "    if importlib.util.find_spec(package) is not None:\n",
    "        return  # ok, package is already installed\n",
    "\n",
    "    if not install_missing_packages:\n",
    "        raise RuntimeError(f\"{package} is not installed!\")\n",
    "\n",
    "    if use_conda:\n",
    "        import conda.cli\n",
    "        conda.cli.main('conda', 'install',  '-y', conda_pkg or package)\n",
    "    else:\n",
    "        import subprocess\n",
    "        import sys            \n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pip_pkg or package])\n",
    "        \n",
    "        \n",
    "# This is to exit cells without error tracebacks (cosmetic purpose)\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "To run all of this notebook, you need the following libraries to be installed:\n",
    "* ImageIO (`imageio` and `imageio-ffmpeg`): for reading images and accessing the webcam\n",
    "* MatPlotLib (`matplotlib`): mainly for displaying images in the notebook\n",
    "* Menpo (`menpo`): for the AAM structures\n",
    "* Menpodetect (`menpodetect`): provides the Dlib face detector\n",
    "* Menpofit (`menpofit`): providing the shape fitter\n",
    "\n",
    "Running the following cell will create a file `aam_demo.yml` that can be used to setup a conda environment containing the required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile aam_demo.yml\n",
    "name: aam_demo\n",
    "channels:\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.6 \n",
    "  - jupyter\n",
    "  - imageio\n",
    "  - imageio-ffmpeg\n",
    "  - matplotlib\n",
    "  - menpo\n",
    "  - menpodetect\n",
    "  - menpofit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the environment, open a shell and type\n",
    "```sh\n",
    "conda env create -f aam_demo.yml\n",
    "```\n",
    "Remember that after running this command you have to activate the environment (Linux/MacOS: `conda activate aam_demo`, Windows: `activate aam_demo`) and then start jupyter in that environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# /images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please make sure you also downloaded the folder images along with its content \n",
    "# and stored it in the same directory as this notebook.\n",
    "from pathlib import Path\n",
    "assert(Path('images').exists())\n",
    "assert(Path('images/obama.jpg').exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Appearance Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset:\n",
    "The pretrained model used in this demo was trained on multiple Datasets:\n",
    "LFPW trainset, HELEN trainset, IBUG and AFW datasets which are hosted in http://ibug.doc.ic.ac.uk/resources/facial-point-annotations/.\n",
    "\n",
    "The (in total) 3283 images contain 68 landmarks that were labeled manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package (Menpo)\n",
    "\n",
    "My personal experience with this package was very clunky.\n",
    "* Input requires importing from file.\n",
    "* Conversion from e.g. numpy array not possible\n",
    "* Menpo image = each pixel has channels for additional information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo - Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import menpo.io as mio\n",
    "from menpodetect import load_dlib_frontal_face_detector\n",
    "from menpofit.aam import load_balanced_frontal_face_fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load detector (dlib)\n",
    "detector = load_dlib_frontal_face_detector()\n",
    "\n",
    "# Load pretrained fitter\n",
    "fitter = load_balanced_frontal_face_fitter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import an image from your images folder as a menpo object\n",
    "image = mio.import_image('images/obama.jpg')\n",
    "\n",
    "# a greyscaled version is required for the facedetection/fitting\n",
    "image_grey = image.as_greyscale()\n",
    "\n",
    "\n",
    "# Detect faces in image = bounding box\n",
    "faces = detector(image_grey)\n",
    "if len(faces) == 0:\n",
    "    print('No face detected')\n",
    "    raise StopExecution\n",
    "else:\n",
    "    print(\"{} detected faces.\".format(len(faces)))\n",
    "\n",
    "\n",
    "# fit mapping on imported image\n",
    "# The bounding box is used in order to align the model's reference shape as first \"guess\" \n",
    "result = fitter.fit_from_bb(image, faces[0], max_iters=(15,5))\n",
    "\n",
    "\n",
    "\n",
    "## visualize the detected face ...\n",
    "if len(faces) > 0:\n",
    "    image_grey.view_landmarks(group='dlib_0', line_colour='red',\n",
    "                         render_markers=False, line_width=4);\n",
    "# ... and the fitted landmarks on top of the original (colored image)\n",
    "result.view(render_initial_shape=False,figure_size=(15,15), final_marker_face_colour='c', marker_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additionally the iterations of the fitting process can be visualized\n",
    "\n",
    "result.view_iterations(figure_size=(10,10),render_legend=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or the final fitted shape by itself\n",
    "result.final_shape.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo - Selfie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (in case tools were not imported before)\n",
    "\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import menpo.io as mio\n",
    "from menpodetect import load_dlib_frontal_face_detector\n",
    "from menpofit.aam import load_balanced_frontal_face_fitter\n",
    "\n",
    "# Load detector (dlib)\n",
    "detector = load_dlib_frontal_face_detector()\n",
    "\n",
    "# Load pretrained fitter\n",
    "fitter = load_balanced_frontal_face_fitter()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = None\n",
    "image = None\n",
    "\n",
    "# open camera, take picture and close camera after\n",
    "try:\n",
    "    camera = imageio.get_reader(f'<video{webcam}>')\n",
    "    image = camera.get_next_data()\n",
    "finally:\n",
    "    if camera is not None:\n",
    "        camera.close()\n",
    "\n",
    "# display picture taken        \n",
    "if image is not None:\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.title(f\"Snapshot {image.shape}\")\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "# save image to current dir in folder images\n",
    "imageio.imwrite('images/webcam.jpg', image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously recorded image and convert to greyscale\n",
    "image_cam = mio.import_image('images/webcam.jpg')\n",
    "image_grey = image_cam.as_greyscale()\n",
    "\n",
    "\n",
    "# Detect faces in image\n",
    "faces = detector(image_grey)\n",
    "if len(faces) == 0:\n",
    "    print('No face detected')\n",
    "    raise StopExecution\n",
    "else:\n",
    "    print(\"{} detected faces.\".format(len(faces)))\n",
    "\n",
    "\n",
    "# fit mapping on recorded image\n",
    "result = fitter.fit_from_bb(image_cam, faces[0], max_iters=(20,5))\n",
    "\n",
    "\n",
    "# visualize the detected face ...\n",
    "if len(faces) > 0:\n",
    "    image_grey.view_landmarks(group='dlib_0', line_colour='red',\n",
    "                         render_markers=False, line_width=4);\n",
    "# ... and the fitted landmarks on top of the original (colored image)\n",
    "result.view(render_initial_shape=False,figure_size=(15,15), final_marker_face_colour='c', marker_size=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Additionally the iterations of the fitting process can be visualized\n",
    "result.view_iterations(figure_size=(15,15),render_legend=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
