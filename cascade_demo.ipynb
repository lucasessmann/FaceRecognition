{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo notebook: Facial landmarking\n",
    "\n",
    "This demo introduces the cascaded regression models for facial landmark detection. \n",
    "* Both stationary as well as live webcam inputs will be used\n",
    "* Both dlib's HOG based frontal face detector and it's 5-point/68-point shape predictors will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets used by dlib's shape predictors\n",
    "* 5-point shape predictor (`shape_predictor_5_face_landmarks.dat.bz2`):\n",
    "    * dlib 5-point face landmark dataset\n",
    "    * Consists of 7198 faces\n",
    "* 68-point shape predictor (`shape_predictor_68_face_landmarks.dat.bz2`):\n",
    "    * i-bug 300-W dataset (with landmark annotations) \n",
    "    * Link: https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/ (however not freely accessible)\n",
    "\n",
    "#### You can find the dlib predictors here:\n",
    "http://dlib.net/files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration (Ulf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General configuration\n",
    "import os\n",
    "\n",
    "# data_directory: str\n",
    "#     Path to a directory to store data.\n",
    "data_directory = '.'\n",
    "\n",
    "# install_missing_packages: bool\n",
    "#     A flag indicating if missing packages should be automatically installed\n",
    "install_missing_packages = True\n",
    "\n",
    "# use_conda: bool\n",
    "#     A flag indicating if conda should be used for software installation.\n",
    "#     If False, pip will be used. The default is to use conda if jupyter\n",
    "#     is run in a conda environment.\n",
    "use_conda = 'CONDA_EXE' in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations (Ulf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An auxiliary function to check for an install packages if missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "def check_package(package, pip_pkg: str = None, conda_pkg: str = None):\n",
    "    \"\"\"Check if a given package is installed. If missing install\n",
    "    it (if global flag `install_missing_packages` is True) either with\n",
    "    pip or with conda (depending on `use_conda`).\n",
    "    \"\"\"\n",
    "    if importlib.util.find_spec(package) is not None:\n",
    "        return  # ok, package is already installed\n",
    "\n",
    "    if not install_missing_packages:\n",
    "        raise RuntimeError(f\"{package} is not installed!\")\n",
    "\n",
    "    if use_conda:\n",
    "        import conda.cli\n",
    "        conda.cli.main('conda', 'install',  '-y', conda_pkg or package)\n",
    "    else:\n",
    "        import subprocess\n",
    "        import sys            \n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pip_pkg or package])\n",
    "        \n",
    "# This is to exit cells without error tracebacks (cosmetic purpose)\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "To run all of this notebook, you need the following libraries to be installed:\n",
    "* ImageIO (`imageio` and `imageio-ffmpeg`): for reading images and accessing the webcam\n",
    "* Scikit-image (`scikit-image`) for some image manipulation\n",
    "* MatPlotLib (`matplotlib`): mainly for displaying images in the notebook\n",
    "* Dlib (`dlib`) providing the HOG face detector\n",
    "* OpenCV (`opencv`) for real time applications\n",
    "* Imutils (`imutils`) for image manipulation with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cascade_demo.yml\n",
    "name: cascade_demo\n",
    "channels:\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.6\n",
    "  - jupyter\n",
    "  - imageio\n",
    "  - imageio-ffmpeg\n",
    "  - matplotlib\n",
    "  - scikit-image\n",
    "  - dlib\n",
    "  - opencv\n",
    "  - imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils import face_utils\n",
    "import dlib\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# initialize dlib's HOG-based face detector \n",
    "hog_detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection Function \n",
    "I use Ulfs Detection function since it increases the performance by rescaling the image. Then, I extended it slightly by returning the detected face rectangles - later, the facial landmark predictor uses these rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import draw, transform, color\n",
    "import time\n",
    "\n",
    "def process(image, detector, upsample_num: int = 1, scale = 1.):\n",
    "    \"\"\"Process an image by applying the given detector and\n",
    "    visually marking detection in that image.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    image: np.ndarray\n",
    "        An array to be interpreted as RGB image (not BGR - the dlib engine\n",
    "        seems to follow the standard color model!).\n",
    "    \n",
    "    detector:\n",
    "        A dlib detector object.\n",
    "    \n",
    "    upsample_num: int\n",
    "        Number of upsamples during detection. Can be any non-negative\n",
    "        integer (including 0).\n",
    "        \n",
    "    scale: float\n",
    "        A factor by which the image is scaled prior to detection.\n",
    "        \n",
    "    Results\n",
    "    -------\n",
    "    image: np.ndarray\n",
    "        The image with detected faces marked\n",
    "        \n",
    "    detections: int\n",
    "        Number of faces detected\n",
    "        \n",
    "    duration: float\n",
    "        Time (in seconds) needed for detection\n",
    "    \n",
    "    rects: the detected rectangled faces \n",
    "    \"\"\"\n",
    "    # Resize image for faster face detection\n",
    "    scaled_image = transform.rescale(image, scale=(scale, scale, 1),\n",
    "                                     preserve_range=True).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    # detect faces in the grayscale image\n",
    "    start = time.time()\n",
    "    rects = detector(scaled_image, upsample_num)\n",
    "    end = time.time()\n",
    "\n",
    "    # decorate the image: loop over the face detections\n",
    "    for rect in rects:\n",
    "        # rect is of type <class 'dlib.rectangle'>\n",
    "        #\n",
    "        # compute the bounding box of the face and draw it on the\n",
    "        # original image\n",
    "        top = max(0, int(rect.top() / scale))\n",
    "        right = min(image.shape[1], int(rect.right() / scale))\n",
    "        bottom = min(image.shape[0], int(rect.bottom() / scale))\n",
    "        left = max(0, int(rect.left() / scale))\n",
    "        image[(top,top+1, bottom-2, bottom-1), left:right] = (0, 255, 0)\n",
    "        image[top:bottom, (left, left+1, right-2, right-1)] = (0, 255, 0)\n",
    "\n",
    "    return image, rects, len(rects), (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting the faces using Ulfs function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imageio.imread('images/LargestSelfie.jpg')   \n",
    "\n",
    "upsample_num = 2\n",
    "scale = 1.0\n",
    "\n",
    "result_img, rects, face_detections, duration = \\\n",
    "process(image.copy(), hog_detector, upsample_num=upsample_num, scale=scale)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(f\"Largest Selfie with Boxes\\n\"\n",
    "          f\"{face_detections} detection{'' if face_detections==1 else 's'}\"\n",
    "          f\" in {duration*1000:.2f} ms\")\n",
    "plt.imshow(result_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 key point landmark predictor (stationary image):\n",
    "* Using the dlib 5 point shape predictor\n",
    "* and the face detection function introduced above <br>\n",
    "The predictor gets the returning face rectangles to analyse and draws 5 circles on the corresponding detection locations indicating the facial key landmarks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create the facial landmark predictor\n",
    "predictor_5 = \"shape_predictor_5_face_landmarks.dat\"\n",
    "\n",
    "predictor = dlib.shape_predictor(predictor_5)\n",
    "\n",
    "# get the input image\n",
    "image = imageio.imread('images/LargestSelfie.jpg')   \n",
    "\n",
    "# Convert it into gray scale (required for the predictor)\n",
    "gray_Input = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# use the dlib detector to detect faces in the image box\n",
    "result_img, rects, face_detections, duration = \\\n",
    "process(image.copy(), hog_detector, upsample_num=upsample_num, scale=scale)\n",
    "\n",
    "# loop over those detected face candidates\n",
    "for (i, detected) in enumerate(rects):\n",
    "    \n",
    "    # find the landmarks within each rectangle by using the dlib predictor\n",
    "    shape = predictor(gray_Input, detected)\n",
    "    \n",
    "    # convert the resulting landmark coordinates (x,y) to a NumPy array\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "    # loop over all landmark coordinates (x,y) and mark them on the image\n",
    "    # using cv2.circle(input_image, center coordinats, circle radius, circle color, circle thickness)\n",
    "    radius = 2\n",
    "    color = (193, 249, 162) # something like mint\n",
    "    thickness = 2\n",
    "    \n",
    "    for (x, y) in shape:\n",
    "        cv2.circle(image, (x, y), radius, color, thickness)\n",
    "\n",
    "\n",
    "        \n",
    "# Plotting \n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(f\"Largest Selfie with landmark predictions\\n\"\n",
    "          f\"Used 5 point detector\\n\")\n",
    "plt.imshow(result_img)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 68 key point landmark predictor (stationary image):\n",
    "* Using the dlib 68 point shape predictor \n",
    "* and the face detection function introduced above <br>\n",
    "The predictor gets the returning face rectangles to analyse and draws 68 circles on the corresponding detection locations indicating the facial key landmarks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the facial landmark predictor\n",
    "predictor_68 = \"shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(predictor_68)\n",
    "\n",
    "# get the input image\n",
    "# https://4.bp.blogspot.com/-aoMqfIsY5Ls/VHIBk6BQ3dI/AAAAAAAAf3Q/cRV668YRm4w/s1600/10700088_1029155283762368_4785788257713012496_o.jpg\n",
    "image = imageio.imread('images/LargestSelfie.jpg')   \n",
    "\n",
    "# Convert it into gray scale (required for the predictor)\n",
    "gray_Input = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# use the dlib detector to detect faces in the image box\n",
    "result_image, rects, detections, duration = \\\n",
    "process(image.copy(), hog_detector, upsample_num=upsample_num, scale=scale)\n",
    "\n",
    "# loop over those detected face candidates\n",
    "for (i, detected) in enumerate(rects):\n",
    "    # find the landmarks within each rectangle by using the dlib predictor\n",
    "    shape = predictor(gray_Input, detected)\n",
    "    # convert the resulting landmark coordinates (x,y) to a NumPy array\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "    # loop over all landmark coordinates (x,y) and mark them on the image\n",
    "    # using cv2.circle(input_image, center coordinats, circle radius, circle color, circle thickness)\n",
    "    radius = 2\n",
    "    color = (193, 249, 162) # something like mint\n",
    "    thickness = 2\n",
    "    \n",
    "    for (x, y) in shape:\n",
    "        cv2.circle(image, (x, y), radius, color, thickness)\n",
    "\n",
    "        \n",
    "        \n",
    "# Plotting\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(f\"Largest Selfie with landmark predictions\\n\"\n",
    "          f\"Used 68 point detector\\n\")\n",
    "plt.imshow(result_img)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial Landmark Detection with live camera images:\n",
    "* Here you can decide whether you want to use the 5 oder the 68 point predictor.\n",
    "* Uses the same structure as the stationary examples\n",
    "* However, using the video capture, aka webcam, as input and predicts the landmark locations while the camera is active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "predictor_5 = \"shape_predictor_5_face_landmarks.dat\"\n",
    "predictor_68 = \"shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# Using the dlib face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Choose between 5 and 68 point predictor here! \n",
    "predictor = 68\n",
    "\n",
    "if predictor == 5:\n",
    "    predictor = dlib.shape_predictor(predictor_5)\n",
    "elif predictor == 68:\n",
    "    predictor = dlib.shape_predictor(predictor_68)\n",
    "else:\n",
    "    print('Choose the right point-predictor!')\n",
    "    raise StopExecution\n",
    "        \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # get the camera input\n",
    "    _, image = cap.read()\n",
    "    # Convert it into gray scale (required for the predictor)\n",
    "    gray_Input = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    # use the dlib detector to detect faces in the image box\n",
    "    faces = detector(gray_Input, 0)\n",
    "    \n",
    "    # loop over those detected face candidates\n",
    "    for (i, detected) in enumerate(faces):\n",
    "        # find the landmarks within each rectangle by using the dlib predictor\n",
    "        shape = predictor(gray_Input, detected)\n",
    "        # convert the resulting landmark coordinates (x,y) to a NumPy array\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "    \n",
    "        # loop over all landmark coordinates (x,y) and mark them on the image\n",
    "        # using cv2.circle(input_image, center coordinats, circle radius, circle color, circle thickness)\n",
    "        radius = 2\n",
    "        color = (193, 249, 162) # something like mint\n",
    "        thickness = 2\n",
    "    \n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), radius, color, thickness)\n",
    "    \n",
    "    # Update and display the output image with all detected facial landmarks \n",
    "    # on the respective face candidate (multiple are possible)\n",
    "    cv2.imshow(\"Window\", image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # Press q to deactivate camera and close window\n",
    "        break\n",
    "        \n",
    "# Deactivate the camera\n",
    "cap.release()\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Necessary for mac users to overcome the window closing barrier\n",
    "for i in range (1,5):\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\uparrow$ Press q to stop! $\\uparrow$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
